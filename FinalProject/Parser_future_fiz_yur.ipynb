{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92d2f79-7bfe-4592-ba1a-65b5608bcb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a7ffd-1029-4b68-8bc4-2cc6ae12b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as rq\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff6015-372c-4028-870a-b0bdbe53f022",
   "metadata": {},
   "source": [
    "# Демонстрация того, как будет происходить процесс совмещения на двух днях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9412618-5e19-4454-a0cf-e22c0d95ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ссылка на данные\n",
    "url1 = \"https://iss.moex.com/iss/analyticalproducts/futoi/securities/si.json?from=2023-11-07&till=2023-11-08&table_type=full\"\n",
    "url2 = \"https://iss.moex.com/iss/analyticalproducts/futoi/securities/si.json?from=2023-11-06&till=2023-11-07&table_type=full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df49ced-8d39-4ebf-9824-9a875770d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отправляем GET-запрос по указанной ссылке\n",
    "response = rq.get(url1)\n",
    "\n",
    "# Проверяем статус ответа\n",
    "if response.status_code == 200:\n",
    "    # Загружаем данные из ответа в переменную data в случае успеха\n",
    "    data = response.json()\n",
    "else:\n",
    "    print(\"Ошибка при получении данных\")\n",
    "    \n",
    "\n",
    "columns = response.json()[\"futoi\"]['columns']\n",
    "\n",
    "data = response.json()[\"futoi\"][\"data\"]\n",
    "\n",
    "df1 = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "\n",
    "# Отправляем GET-запрос по указанной ссылке\n",
    "response = rq.get(url2)\n",
    "\n",
    "# Проверяем статус ответа\n",
    "if response.status_code == 200:\n",
    "    # Загружаем данные из ответа в переменную data в случае успеха\n",
    "    data = response.json()\n",
    "else:\n",
    "    print(\"Ошибка при получении данных\")\n",
    "\n",
    "\n",
    "columns = response.json()[\"futoi\"]['columns']\n",
    "\n",
    "data = response.json()[\"futoi\"][\"data\"]\n",
    "\n",
    "df2 = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984879f5-fc18-4cb3-a5a7-17aec9331ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.sort_values(by=['ticker', 'tradedate','tradetime']).reset_index().drop('index', axis=1))\n",
    "print(len(np.array(df1['ticker'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e55ad53-d4c4-460e-b946-a0c329193bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sort_values(by=['ticker', 'tradedate', 'tradetime']).reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b913bf-ddef-44df-b662-480d0126b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.array(df2['ticker'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46119e7-10c9-4258-9a9a-4256d841722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df1, df2]\n",
    "\n",
    "result = pd.concat(frames).sort_values(by=['ticker', 'tradedate', 'tradetime']).reset_index().drop('index', axis=1)\n",
    "filename = \"test_date.csv\"\n",
    "result.to_csv(filename, sep=',', index=False, encoding='utf-8')\n",
    "\n",
    "print(result)\n",
    "\n",
    "print(len(np.array(result['ticker'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd96785-8d91-40b0-939d-b2179b04869c",
   "metadata": {},
   "source": [
    "Далее будет пробегать по массиву дат и таким образом сформируем всю таблицу"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8510040-967f-4be1-9e00-8a6631aa510d",
   "metadata": {},
   "source": [
    "Ниже я задаю массив всех дат"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e13737b-776e-4f66-a1f1-3e418ea79bcf",
   "metadata": {},
   "source": [
    "# Парсинг данных о позиций"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abde0d12-4db4-4fbc-9ab7-f7d06d3ad487",
   "metadata": {},
   "source": [
    "Сначала мы создаём массив, который содержить все даты, за которые мы хотим получить данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d48f5-16bd-4ba9-9b74-5675afafd480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_date = datetime(2020, 5, 8)\n",
    "end_date = datetime.now()\n",
    "\n",
    "current_date = start_date\n",
    "array_date = []\n",
    "while current_date <= end_date:\n",
    "    array_date += [current_date.strftime(\"%Y-%m-%d\")]\n",
    "    current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba53871-b369-45c3-a011-b358dca6c333",
   "metadata": {},
   "source": [
    "Тут мы формируем массив из дней, а затем, если сервер работает хорошо, то возвращаем данные за весь промежуток от 5 августа 2020 до сегодняшнего дня. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf91a1a-a841-435b-93b8-f76aa355790a",
   "metadata": {},
   "source": [
    "Если сервер перестаёт отвечать, тогда полученные данные мы собираем в файл и при повторном запуске программа проверить наши файлы и начнёт с последнего записанного дня."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edcff02-0488-4eaf-a786-9e3a30a59d62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T19:32:17.593040Z",
     "iopub.status.busy": "2023-12-01T19:32:17.592042Z",
     "iopub.status.idle": "2023-12-01T19:32:17.613037Z",
     "shell.execute_reply": "2023-12-01T19:32:17.612038Z",
     "shell.execute_reply.started": "2023-12-01T19:32:17.593040Z"
    }
   },
   "source": [
    "В качестве отладки печатается дата дня, который мы сейчас получаем. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84838e65-1b77-4d33-b6a5-afbd54555f22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_new_day(date_today: str, ticker_name: str):\n",
    "    date_yesterday = (datetime.strptime(date_today, '%Y-%m-%d') - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    url = f\"https://iss.moex.com/iss/analyticalproducts/futoi/securities/{ticker_name}.json?from={date_today}&till={date_today}&table_type=full\"\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Ваш код, который может вызвать ошибку\n",
    "            response = rq.get(url)\n",
    "            # break  # Если ошибки не возникло, выходим из цикла\n",
    "        except Exception as e:\n",
    "            # Обработка других исключений\n",
    "            print(f\"Произошла ошибка: {e}\")\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Проверяем статус ответа\n",
    "    if response.status_code != 200:\n",
    "        print(\"Ошибка при получении данных\")\n",
    "        add_new_day(date_today)\n",
    "\n",
    "    df_for_add = pd.DataFrame(response.json()[\"futoi\"][\"data\"], columns=response.json()[\"futoi\"]['columns'])\n",
    "    df_for_add.sort_values(by=['ticker', 'tradedate','tradetime']).reset_index().drop('index', axis=1)\n",
    "   \n",
    "    return df_for_add\n",
    "\n",
    "# ticker_names=['si', 'br', 'ri', 'eu', 'mx', 'sr', 'ox', 'gz', 'yn', 'fv', 'vi', 'lk']\n",
    "ticker_names=['sr', 'gz', 'lk', 'vb', 'rn', 'mn', 'af', 'al', 'sn', 'yn', 'tt', 'nm', 'hy', 'me', 'fv', 'gk', 'mg', 'ml']\n",
    "\n",
    "for ticker_name in ticker_names:\n",
    "    if Path(f\"{ticker_name}_full_date.csv\").exists():\n",
    "        df = pd.read_csv(f\"{ticker_name}_full_date.csv\")\n",
    "        last_valid_date_index = df['tradedate'].last_valid_index()\n",
    "        last_valid_date_value  = df['tradedate'][last_valid_date_index]\n",
    "        date_tomorrow = (datetime.strptime(last_valid_date_value, '%Y-%m-%d') + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "        print(date_tomorrow)\n",
    "        if(not date_tomorrow in array_date):\n",
    "            pass\n",
    "        else:\n",
    "            df_array = [df]\n",
    "            for date in array_date[array_date.index(date_tomorrow)+1:]:\n",
    "                df_array += [add_new_day(date, ticker_name)]\n",
    "                print(date)\n",
    "            df = pd.concat(df_array).sort_values(by=['ticker', 'tradedate', 'tradetime']).reset_index().drop('index', axis=1)\n",
    "            print(df)\n",
    "            filename = f\"{ticker_name}_full_date.csv\"\n",
    "            df.to_csv(filename, sep=',', index=False, encoding='utf-8')\n",
    "    else:\n",
    "        print(f\"Файл '{ticker_name}_full_date.csv' не существует.\")\n",
    "        df_array = []\n",
    "        for date in array_date:\n",
    "            df_array += [add_new_day(date, ticker_name)]\n",
    "            print(date)\n",
    "        df = pd.concat(df_array).sort_values(by=['ticker', 'tradedate', 'tradetime']).reset_index().drop('index', axis=1)\n",
    "        print(df)\n",
    "        filename = f\"{ticker_name}_full_date.csv\"\n",
    "        df.to_csv(filename, sep=',', index=False, encoding='utf-8')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f392f195-2f64-4d24-af80-c7bab93ab885",
   "metadata": {},
   "source": [
    "Удаление повторяющихся данных (в силу того, как МосБиржа возвращала данные (в выходные дни вместо пустого запроса она возвращает последнюю цену за последний рабочий день, то есть 14*20 одинаковых записей, в силу чего эта ячейка позволяла сэкономить, примерно, 300 МБ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da8fc23-3c8d-409b-b49b-239032dca593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker_names=['si', 'br', 'ri', 'eu', 'mx', 'sr', 'ox', 'gz', 'yn', 'fv', 'vi', 'lk']\n",
    "\n",
    "for ticker_name in ticker_names:\n",
    "    your_file = f\"{ticker_name}_full_date.csv\" \n",
    "# Загрузка данных\n",
    "    df = pd.read_csv(your_file)\n",
    "\n",
    "# Удаление повторяющихся строк\n",
    "    unique_rows = df.drop_duplicates()\n",
    "\n",
    "# Сохранение результата\n",
    "    unique_rows.to_csv(your_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7e086b-8c36-4911-b493-25120e3d0626",
   "metadata": {},
   "source": [
    "Итоговые данные не идеальны, поэтому мы их будем обрабатывать в других данных."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
